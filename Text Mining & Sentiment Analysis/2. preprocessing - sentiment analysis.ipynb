{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "\n",
    "import string\n",
    "import random\n",
    "import os\n",
    "\n",
    "# general \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn \n",
    "import string\n",
    "import random\n",
    "import os\n",
    "import spacy\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "#from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"path to/horoscopedotcom.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horoscope = []\n",
    "date = []\n",
    "for line in range(len(df)):\n",
    "    tmp = df[\"Horoscope\"][line].split('-')\n",
    "    date.append(tmp[0])\n",
    "    horoscope.append(' '.join(tmp[1:]))\n",
    "\n",
    "df['Horoscope'] = horoscope\n",
    "df['Date'] = date\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Date\"].str.contains(\"Feb 4, 2023\") == False] #Remove horoscopes of Feb 4, 2023\n",
    "df=df.reset_index()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sign\"].value_counts() #331 horoscopes in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Horoscope\"].value_counts() #two horoscopes are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset = ['Horoscope', 'Sign'], keep='first', inplace=True)\n",
    "df.shape #1 duplicate dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count toal number of characters and mean length of an horoscope\n",
    "count = df['Horoscope'].str.split().str.len()\n",
    "count.index = count.index.astype(str) + ' words:'\n",
    "count.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of words:', count.sum(), 'words')\n",
    "print('Mean number of words per horoscope:', round(count.mean(), 2), 'words')\n",
    "\n",
    "df['horoscope_length'] = df['Horoscope'].str.len()\n",
    "print('Total length of dataset is:', df.horoscope_length.sum(), 'characters')\n",
    "\n",
    "print('Mean Length of an horoscope is:', round(df.horoscope_length.mean(), 0), 'characters')\n",
    "df = df.drop(['horoscope_length'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove non-letters\n",
    "df['tidy_horoscope'] = df['Horoscope'].str.replace('[^a-zA-Z#]', ' ') # [^a-zA-Z#] --> non letter\n",
    "\n",
    "#lower the text \n",
    "df['tidy_horoscope'] = df['tidy_horoscope'].str.lower()\n",
    "\n",
    "#remove words with length =1 \n",
    "df['tidy_horoscope'] = df['tidy_horoscope'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stopwords and custom stopwords\n",
    "# prepare stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['aries', 'taurus', 'gemini', 'cancer', 'leo', 'virgo', 'libra', 'scorpio', 'saggitarius','sagittarius', 'capricorn', 'acquarius','pisces', 'aquarius', 'today'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(horoscopes):\n",
    "    return [[word for word in simple_preprocess(str(horoscope)) if word not in stop_words] for horoscope in horoscopes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['tidy_horoscope'] = remove_stopwords(df['tidy_horoscope'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing word_tokenize from nltk\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['horoscope_token'] = df['tidy_horoscope']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the frequency distinct in the tokens\n",
    "# Importing FreqDist library from nltk and passing token into FreqDist\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "words=[]\n",
    "for oroscopo in df.index:\n",
    "    for parola in range(len(df['horoscope_token'][oroscopo])):\n",
    "        words.append(df['horoscope_token'][oroscopo][parola])\n",
    "\n",
    "\n",
    "fdist = FreqDist(words)\n",
    "fdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the frequency of top 10 words\n",
    "fdist1 = fdist.most_common(10)\n",
    "fdist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming: normalizing words into its base form or root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Porterstemmer from nltk library\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()\n",
    "\n",
    "horoscope_stemming = []\n",
    "for riga in df.index:\n",
    "    horoscope_stemming_tmp= []\n",
    "    for i in range(len(df['horoscope_token'][riga])):\n",
    "        tmp = pst.stem(df['horoscope_token'][riga][i])\n",
    "        horoscope_stemming_tmp.append(tmp)\n",
    "    horoscope_stemming.append(horoscope_stemming_tmp)\n",
    "\n",
    "df['horoscope_stemming'] = horoscope_stemming\n",
    "df.head()\n",
    "#df['stemmed'] = df['lemmatized'].apply(lambda x: [stemmer.stem(y) for y in x])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Lemmatizer library from nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "horoscope_lemmatize = []\n",
    "for riga in df.index:\n",
    "    horoscope_lemmatize_tmp= []\n",
    "    for i in range(len(df['horoscope_token'][riga])):\n",
    "        tmp1 = lemmatizer.lemmatize(df['horoscope_token'][riga][i])\n",
    "        horoscope_lemmatize_tmp.append(tmp1)\n",
    "    horoscope_lemmatize.append(horoscope_lemmatize_tmp)\n",
    "\n",
    "df['horoscope_lemmatize_nltk'] = horoscope_lemmatize\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Lemmatization\n",
    "def lemmatization(horoscopes, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    horoscope_out = []\n",
    "    for sent in horoscopes:\n",
    "        doc = nlp(' '.join(sent))\n",
    "        horoscope_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return horoscope_out\n",
    "\n",
    "df['horoscope_lemmatize'] = pd.Series(lemmatization(df['horoscope_token'], allowed_postags=['NOUN', 'ADJ']))\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_no_stop_stem'] = remove_stopwords(df['horoscope_stemming'])\n",
    "df['tokens_no_stop_lem'] = remove_stopwords(df['horoscope_lemmatize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of speech tagging (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#horoscope_pos = []\n",
    "#for riga in df.index:\n",
    "#    horoscope_pos_tmp= []\n",
    "#    for i in range(len(df['horoscope_token'][riga])):\n",
    "#        tmp1 = nltk.pos_tag(df['horoscope_token'][i])\n",
    "#        horoscope_pos_tmp.append(tmp1)\n",
    "#    horoscope_pos.append(horoscope_pos_tmp)\n",
    "\n",
    "#df['horoscope_pos'] = horoscope_pos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word CLoud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud\n",
    "\n",
    "def rejoin_words(row):\n",
    "    words = row['tokens_no_stop_lem']\n",
    "    joined_words = (' '.join(words))\n",
    "    return joined_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_stop_joined'] = df.apply(rejoin_words, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join([text for text in df['no_stop_joined']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=900, height=600, random_state=21, max_font_size=110, background_color='ghostwhite', max_words=200, colormap='Dark2').generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning effects - Length of horoscopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['horoscope_length'] = df['Horoscope'].str.len()\n",
    "df['cleaned_horoscope_length'] = df['no_stop_joined'].str.len()\n",
    "df_lengths = df[['horoscope_length', 'cleaned_horoscope_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df_lengths.horoscope_length\n",
    "x2 = df_lengths.cleaned_horoscope_length\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.suptitle('Length of horoscope as number of characters', fontsize = 14, fontweight = 'bold')\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.distplot(x1, color='black', label='No. characters', bins=35, hist_kws={'alpha':0.5, 'rwidth':0.8})\n",
    "plt.title('Original Horoscope', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Number of characters', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xlim([0, 400])\n",
    "\n",
    "# Chart 2: Derivative Function\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.distplot(x2, color='black', label='No. characters', bins=17, hist_kws={'alpha':0.5, 'rwidth':0.8})\n",
    "plt.title('Cleaned horoscopes', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Number of horoscopes', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xlim([0, 400])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['horoscope_words'] = df['Horoscope'].str.split().str.len()\n",
    "df['cleaned_horoscope_words'] = df['no_stop_joined'].str.split().str.len()\n",
    "df_lengths = df[['horoscope_words', 'cleaned_horoscope_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = df_lengths.horoscope_words\n",
    "x_2 = df_lengths.cleaned_horoscope_words\n",
    "plt.figure(figsize = (15, 6))\n",
    "plt.suptitle('Length of horoscope as number of words.', fontsize=14, fontweight='bold')\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "sns.distplot(x_1, color='black', label='No. Words', bins=25, hist_kws={'alpha':0.5, 'rwidth':0.8})\n",
    "plt.title('Original Horoscopes', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Number of words', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xlim([0, 70])\n",
    "\n",
    "# Chart 2: Derivative Function\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.distplot(x_2, color='black', label='No. Words', bins=15, hist_kws={'alpha':0.5, 'rwidth':0.8})\n",
    "plt.title('Cleaned Horoscopes', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Number of words', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xlim([0, 70])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 25 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = pd.Series(np.concatenate([x.split() for x in df.no_stop_joined])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.Series.to_frame(word_freq)\n",
    "word_df['word'] = list(word_df.index)\n",
    "word_df.reset_index(drop=True, inplace=True)\n",
    "word_df.columns = ['freq', 'word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = word_df['word'].head(25)\n",
    "freq = word_df['freq'].head(25)\n",
    "index = np.arange(len(freq))\n",
    "\n",
    "print('Unique words:', len(word_df))\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.bar(index, freq, alpha=0.8, color='black')\n",
    "plt.xlabel('Words', fontsize=13)\n",
    "plt.ylabel('Frequency', fontsize=13)\n",
    "plt.xticks(index, label, fontsize=11, rotation=90, fontweight='bold')\n",
    "plt.title('Top 25 Words after preprocessing', fontsize=12, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   CUSTOM STOPWORDS\n",
    "\n",
    "stop_words.extend(['aries', 'taurus', 'gemini', 'cancer', 'leo', 'virgo', 'libra', 'scorpio', 'saggitarius','sagittarius', 'capricorn', 'acquarius','pisces', 'aquarius', 'today', 'could', 'might', 'may', 'day', 'thing', 'likely', 'perhaps', 'probably'])\n",
    "\n",
    "df['tokens_no_stop_stem'] = remove_stopwords(df['horoscope_stemming'])\n",
    "df['tokens_no_stop_lem'] = remove_stopwords(df['horoscope_lemmatize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud\n",
    "\n",
    "def rejoin_words(row):\n",
    "    words = row['tokens_no_stop_lem']\n",
    "    joined_words = (' '.join(words))\n",
    "    return joined_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_stop_joined'] = df.apply(rejoin_words, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join([text for text in df['no_stop_joined']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=900, height=600, random_state=21, max_font_size=110, background_color='ghostwhite', max_words=200, colormap='Dark2').generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = pd.Series(np.concatenate([x.split() for x in df.no_stop_joined])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.Series.to_frame(word_freq)\n",
    "word_df['word'] = list(word_df.index)\n",
    "word_df.reset_index(drop=True, inplace=True)\n",
    "word_df.columns = ['freq', 'word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = word_df['word'].head(25)\n",
    "freq = word_df['freq'].head(25)\n",
    "index = np.arange(len(freq))\n",
    "\n",
    "print('Unique words:', len(word_df))\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.bar(index, freq, alpha=0.8, color='black')\n",
    "plt.xlabel('Words', fontsize=13)\n",
    "plt.ylabel('Frequency', fontsize=13)\n",
    "plt.xticks(index, label, fontsize=11, rotation=90, fontweight='bold')\n",
    "plt.title('Top 25 Words after preprocessing (NOUNS and ADJ)', fontsize=12, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk sentiment analysis\n",
    "#from nltk.sentiment.sentiment_analyzer import SentimentAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "for sentence in df.index:\n",
    "  ss = sid.polarity_scores(df['Horoscope'][sentence])\n",
    "  for k in sorted(ss):\n",
    "    print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying to all sentences\n",
    "def sid_compound(text):\n",
    "  sid = SentimentIntensityAnalyzer()\n",
    "  ss = sid.polarity_scores(text)\n",
    "  return(ss['compound'])\n",
    "\n",
    "def sid_pos(text):\n",
    "  sid = SentimentIntensityAnalyzer()\n",
    "  ss = sid.polarity_scores(text)\n",
    "  return(ss['pos'])\n",
    "\n",
    "def sid_neg(text):\n",
    "  sid = SentimentIntensityAnalyzer()\n",
    "  ss = sid.polarity_scores(text)\n",
    "  return(ss['neg'])\n",
    "\n",
    "def sid_neu(text):\n",
    "  sid = SentimentIntensityAnalyzer()\n",
    "  ss = sid.polarity_scores(text)\n",
    "  return(ss['neu'])\n",
    "\n",
    "\n",
    "df['sid_score'] = df['Horoscope'].apply(sid_compound)\n",
    "df['sid_pos'] = df['Horoscope'].apply(sid_pos)\n",
    "df['sid_neg'] = df['Horoscope'].apply(sid_neg)\n",
    "df['sid_neu'] = df['Horoscope'].apply(sid_neu)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('positive:', df.sid_pos.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('negative:', df.sid_neg.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('neutre:', df.sid_neu.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textblob sentiment analysis\n",
    "from textblob import TextBlob\n",
    "def detect_polarity(text):\n",
    "    return TextBlob(text).sentiment\n",
    "\n",
    "for sentence in df.index:\n",
    "    print(df['Horoscope'][sentence])\n",
    "    print(detect_polarity(df['Horoscope'][sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying to all sentences\n",
    "def detect_polarity2(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def detect_subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "df['sid_score'] = df['Horoscope'].apply(sid_compound)\n",
    "df['tb_score'] = df['Horoscope'].apply(detect_polarity2)\n",
    "df['tb_score_detect_subjectivity'] = df['Horoscope'].apply(detect_subjectivity)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphing results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"TextBlob vs. Vader\")\n",
    "plt.xlabel(\"TextBlob - Compound score\")\n",
    "plt.ylabel(\"Vader - Compound score\")\n",
    "plt.axhline(color='black', linestyle='-')\n",
    "plt.axvline(color='black', linestyle='-')\n",
    "plt.rcParams['figure.figsize'] = [15,10] #altezza,lunghezza\n",
    "plt.xlim(-1,1)\n",
    "plt.scatter(x=df['tb_score'], y=df['sid_score'], marker=\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=df['sid_score'], alpha=0.5) \n",
    "\n",
    "plt.legend()\n",
    "plt.xlim(-1,1)\n",
    "plt.title('Compound score (VADER)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=df['tb_score_detect_subjectivity'], alpha=0.5, label='Subjectivity') \n",
    "\n",
    "plt.legend()\n",
    "plt.title('Subjectivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(x=df['tb_score'], alpha=0.5) \n",
    "plt.legend()\n",
    "plt.xlim(-1,1)\n",
    "plt.title('Compound score (TextBlob)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cce27c8212bf6c5aa96f33a3d1153887721b66c5c8cb9adeaa83cce09196b75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
