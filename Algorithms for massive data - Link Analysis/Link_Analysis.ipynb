{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Amazon US Customer Reviews - Link Analysis"
      ],
      "metadata": {
        "id": "71t2bqynkDbA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KLXzZ2Ea9Vh"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import json\n",
        "import getpass\n",
        "\n",
        "# Prompt the user for input\n",
        "use_upload = input('Do you want to upload the Kaggle credentials file? (y/n): ')\n",
        "if use_upload.lower() == 'y':\n",
        "    # Upload the file\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Rename the file to KaggleCredential.json\n",
        "    for name in uploaded.keys():\n",
        "        if 'kaggle' in name.lower():\n",
        "            os.rename(name, 'KaggleCredential.json')\n",
        "            break\n",
        "else:\n",
        "    # Manually input the credentials\n",
        "    username = input('Enter your Kaggle username: ')\n",
        "    password = getpass.getpass('Enter your Kaggle key: ')\n",
        "\n",
        "    # Save the credentials to a JSON file\n",
        "    credentials = {'username': username, 'key': password}\n",
        "    with open('KaggleCredential.json', 'w') as f:\n",
        "        json.dump(credentials, f)\n",
        "\n",
        "# Load the credentials from the JSON file\n",
        "with open('KaggleCredential.json', 'r') as f:\n",
        "    credentials = json.load(f)\n",
        "\n",
        "# Get the Kaggle username from the credentials\n",
        "username = credentials['username']\n",
        "password = credentials['key']\n",
        "print(username)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import json\n",
        "\n",
        "# Save your credentials to a JSON file\n",
        "credentials = {'username': username, 'key': password}\n",
        "kaggle_dir = '/root/.kaggle'\n",
        "if not os.path.exists(kaggle_dir):\n",
        "    os.makedirs(kaggle_dir)\n",
        "with open(os.path.join(kaggle_dir, 'kaggle.json'), 'w') as f:\n",
        "    json.dump(credentials, f)\n",
        "\n",
        "# Set the file permissions to read/write only for the owner\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ncn-qW0kbMwq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kaggle\n",
        "datasets = !kaggle datasets list -s 'Amazon US Customer Reviews'\n",
        "datasets"
      ],
      "metadata": {
        "id": "676Ap6JRbR9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle.api.dataset_list_files('cynthiarempel/amazon-us-customer-reviews-dataset').files #list of file in main dataset"
      ],
      "metadata": {
        "id": "QWAtKd4seNjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import kaggle\n",
        "import zipfile\n",
        "\n",
        "# Authenticate Kaggle API\n",
        "kaggle.api.authenticate()"
      ],
      "metadata": {
        "id": "wIqp12HRcApx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle.api.dataset_download_file('cynthiarempel/amazon-us-customer-reviews-dataset','amazon_reviews_us_Digital_Software_v1_00.tsv') # choose dataset among the ones above"
      ],
      "metadata": {
        "id": "xcnhsevyedj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the zip file to the current working directory (i.e., the root directory in Colab)\n",
        "with zipfile.ZipFile('amazon_reviews_us_Digital_Software_v1_00.tsv.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()  # Extract to the current directory"
      ],
      "metadata": {
        "id": "Unh-lC3C4sgL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install pyspark\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql import Window\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "                    .appName(\"Malchiodi's Project\") \\\n",
        "                    .getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "id": "5e_ouU-fi8GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product Linkage"
      ],
      "metadata": {
        "id": "JId6csLynpNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.sparkContext.textFile('amazon_reviews_us_Digital_Software_v1_00.tsv', minPartitions=8) # import as rdd dataset\n",
        "#df1 = spark.sparkContext.textFile('amazon_reviews_us_Digital_Software_v1_00.tsv', minPartitions=8)\n",
        "#df = spark.sparkContext.union([df0, df1])"
      ],
      "metadata": {
        "id": "BhMAuE1PfLsr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_data(line):\n",
        "    fields = line.split(\"\\t\")\n",
        "    return fields[1], fields[3] #keep only customer and product id columns"
      ],
      "metadata": {
        "id": "tKdiYjKFjLZP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.map(parse_data).groupByKey().mapValues(list) # customer linkage --> df.map(parse_data).map(lambda x: (x[1], x[0])).groupByKey().mapValues(list)"
      ],
      "metadata": {
        "id": "xm7flWIbvzD5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.filter(lambda x: len(x[1])>1).map(lambda x: x) # keep only (k, v) with more than one v --> product bought by more than one customer  / customer who bought more than one product"
      ],
      "metadata": {
        "id": "Slve_SPBjjAD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "def combination(row): # define every possible linkage: e.g. (0, [1, 2, 3]) --> (1, 2), (1, 3), (2, 3), (2, 1), (3, 2), (3, 1)\n",
        "    l = row[1]\n",
        "    k = row[0]\n",
        "    res1 = [(v[0], v[1]) for v in itertools.combinations(l, 2)]\n",
        "    to_add = []\n",
        "    for x in res1:\n",
        "        to_add.append(tuple(reversed(x)))\n",
        "    return (res1+to_add) "
      ],
      "metadata": {
        "id": "BVDIFWi3cDwC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.map(lambda x: combination(x)).flatMap(lambda l: l) #from list of list to list"
      ],
      "metadata": {
        "id": "at5t1PAgfPLz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_nodes = df.groupByKey().count() # how many single nodes?"
      ],
      "metadata": {
        "id": "6VkzpVJgjrvE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2id = df\n",
        "# compute the out-degree for each node\n",
        "id2degree = id2id.countByKey() #count by key --> for each key, how many link?"
      ],
      "metadata": {
        "id": "9C4L4GIdjs4F"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prods = list(id2degree.keys())\n",
        "p = 1/(total_nodes) \n",
        "p2diz = {}\n",
        "for prod in prods:\n",
        "    p2diz[prod] = p"
      ],
      "metadata": {
        "id": "1cnMAlxNjvS-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute sparse transition matrix\n",
        "P = id2id.map(lambda x:(x[0],x[1],1/id2degree[x[0]])) #(i, j, Mij)\n",
        "PT = P.map(lambda x: (x[1],x[0],x[2])) #(j, i , Mij)"
      ],
      "metadata": {
        "id": "wJqX6rlojwpv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P*p for some iteration\n",
        "for i in range(70):\n",
        "    new_p = PT.map(lambda x:(x[0],(x[2]*p2diz[x[1]])))\\\n",
        "              .reduceByKey(lambda x,y: x+y)\\\n",
        "              .collect()\n",
        "    for idx,prb in new_p:\n",
        "        p2diz[idx] = prb"
      ],
      "metadata": {
        "id": "bF3Kj13ajyQP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p2diz_sort = sorted(p2diz.items(), key=lambda x:x[1], reverse=True) #order the diz by probability and print the most recurrent products "
      ],
      "metadata": {
        "id": "eSs20Dnpj0Gg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Most quoted products:')\n",
        "for kv in range(len(p2diz_sort[:20])):\n",
        "    print(f'With prob: {p2diz_sort[kv][1]}, you take product with code: {p2diz_sort[kv][0]}')"
      ],
      "metadata": {
        "id": "GwsaY1wEj1jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customer linkage"
      ],
      "metadata": {
        "id": "O6ycuRL6gwcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.sparkContext.textFile('amazon_reviews_us_Digital_Software_v1_00.tsv', minPartitions=8)"
      ],
      "metadata": {
        "id": "IL3vD7d4j22y"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_data(line):\n",
        "    fields = line.split(\"\\t\")\n",
        "    return fields[1], fields[3] #keep only customer and product id columns"
      ],
      "metadata": {
        "id": "yMG31qOrk3aO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.map(parse_data).map(lambda x: (x[1], x[0])).groupByKey().mapValues(list)"
      ],
      "metadata": {
        "id": "JQeJ4Qvkk3aO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.filter(lambda x: len(x[1])>1).map(lambda x: x)"
      ],
      "metadata": {
        "id": "SA4ZZWyvk3aP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "def combination(row):\n",
        "    l = row[1]\n",
        "    k = row[0]\n",
        "    res1 = [(v[0], v[1]) for v in itertools.combinations(l, 2)]\n",
        "    to_add = []\n",
        "    for x in res1:\n",
        "        to_add.append(tuple(reversed(x)))\n",
        "    return (res1+to_add)"
      ],
      "metadata": {
        "id": "MAhCltXeg5BC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.map(lambda x: combination(x)).flatMap(lambda l: l)"
      ],
      "metadata": {
        "id": "STT45o4Hg5DP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_nodes = df.groupByKey().count()"
      ],
      "metadata": {
        "id": "_i2TZ3-ok3aP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2id = df\n",
        "# compute the out-degree for each node\n",
        "id2degree = id2id.countByKey()"
      ],
      "metadata": {
        "id": "T1-Fg9xqk3aP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prods = list(id2degree.keys())\n",
        "p = 1/(total_nodes)\n",
        "p2diz = {}\n",
        "for prod in prods:\n",
        "    p2diz[prod] = p"
      ],
      "metadata": {
        "id": "RzOKHRCLk3aP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute sparse transition matrix\n",
        "P = id2id.map(lambda x:(x[0],x[1],1/id2degree[x[0]]))\n",
        "PT = P.map(lambda x: (x[1],x[0],x[2]))"
      ],
      "metadata": {
        "id": "6ibUgyIxk3aP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P*p for some iteration\n",
        "for i in range(70):\n",
        "    new_p = PT.map(lambda x:(x[0],(x[2]*p2diz[x[1]])))\\\n",
        "              .reduceByKey(lambda x,y: x+y)\\\n",
        "              .collect()\n",
        "    for idx,prb in new_p:\n",
        "        p2diz[idx] = prb"
      ],
      "metadata": {
        "id": "cl49TGb_k3aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p2diz_sort = sorted(p2diz.items(), key=lambda x:x[1], reverse=True)"
      ],
      "metadata": {
        "id": "EogLbc_Rk3aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Most quoted customers:')\n",
        "for kv in range(len(p2diz_sort[:20])):\n",
        "    print(f'With prob: {p2diz_sort[kv][1]}, you are similar to customer with code: {p2diz_sort[kv][0]}')"
      ],
      "metadata": {
        "id": "zEip_jYsk3aP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}