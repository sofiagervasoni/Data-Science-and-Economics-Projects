{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Amazon US Customer Reviews - Market Basket Analaysis"
      ],
      "metadata": {
        "id": "5WMM5Ax0Su6s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KLXzZ2Ea9Vh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59d0ef62-25d2-4155-8ff3-683a981e4ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do you want to upload the Kaggle credentials file? (y/n): n\n",
            "Enter your Kaggle username: lucapaoletti\n",
            "Enter your Kaggle key: ··········\n",
            "lucapaoletti\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import json\n",
        "import getpass\n",
        "\n",
        "# Prompt the user for input\n",
        "use_upload = input('Do you want to upload the Kaggle credentials file? (y/n): ')\n",
        "if use_upload.lower() == 'y':\n",
        "    # Upload the file\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Rename the file to KaggleCredential.json\n",
        "    for name in uploaded.keys():\n",
        "        if 'kaggle' in name.lower():\n",
        "            os.rename(name, 'KaggleCredential.json')\n",
        "            break\n",
        "else:\n",
        "    # Manually input the credentials\n",
        "    username = input('Enter your Kaggle username: ')\n",
        "    password = getpass.getpass('Enter your Kaggle key: ')\n",
        "\n",
        "    # Save the credentials to a JSON file\n",
        "    credentials = {'username': username, 'key': password}\n",
        "    with open('KaggleCredential.json', 'w') as f:\n",
        "        json.dump(credentials, f)\n",
        "\n",
        "# Load the credentials from the JSON file\n",
        "with open('KaggleCredential.json', 'r') as f:\n",
        "    credentials = json.load(f)\n",
        "\n",
        "# Get the Kaggle username from the credentials\n",
        "username = credentials['username']\n",
        "password = credentials['key']\n",
        "print(username)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import json\n",
        "\n",
        "# Save your credentials to a JSON file\n",
        "credentials = {'username': username, 'key': password}\n",
        "kaggle_dir = '/root/.kaggle'\n",
        "if not os.path.exists(kaggle_dir):\n",
        "    os.makedirs(kaggle_dir)\n",
        "with open(os.path.join(kaggle_dir, 'kaggle.json'), 'w') as f:\n",
        "    json.dump(credentials, f)\n",
        "\n",
        "# Set the file permissions to read/write only for the owner\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ncn-qW0kbMwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kaggle\n",
        "datasets = !kaggle datasets list -s 'Amazon US Customer Reviews'\n",
        "datasets"
      ],
      "metadata": {
        "id": "676Ap6JRbR9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e541171b-854f-499a-9cb7-5b679ea6a0d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ref                                                 title                               size  lastUpdated          downloadCount  voteCount  usabilityRating  ',\n",
              " '--------------------------------------------------  ----------------------------------  ----  -------------------  -------------  ---------  ---------------  ',\n",
              " 'cynthiarempel/amazon-us-customer-reviews-dataset    Amazon US Customer Reviews Dataset  21GB  2021-06-16 20:07:46           3182         31  1.0              ',\n",
              " 'mahran34/amazon-customer-reviews-for-some-products  Amazon reviews                       1MB  2021-10-23 17:49:34             50          1  0.47058824       ',\n",
              " 'washingtongold/amazon-us-software-reviews           Amazon US Software Reviews          99MB  2022-02-20 16:56:08             36          1  0.5882353        ']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle.api.dataset_list_files('cynthiarempel/amazon-us-customer-reviews-dataset').files #list of file in main dataset"
      ],
      "metadata": {
        "id": "QWAtKd4seNjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ce74649-c475-49dd-db7d-ead779d2f51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[amazon_reviews_us_Grocery_v1_00.tsv,\n",
              " amazon_reviews_us_Mobile_Electronics_v1_00.tsv,\n",
              " amazon_reviews_us_Video_DVD_v1_00.tsv,\n",
              " amazon_reviews_us_Outdoors_v1_00.tsv,\n",
              " amazon_reviews_us_Software_v1_00.tsv,\n",
              " amazon_reviews_us_Digital_Video_Download_v1_00.tsv,\n",
              " amazon_reviews_us_Mobile_Apps_v1_00.tsv,\n",
              " amazon_reviews_multilingual_US_v1_00.tsv,\n",
              " amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv,\n",
              " amazon_reviews_us_Digital_Software_v1_00.tsv,\n",
              " amazon_reviews_us_Electronics_v1_00.tsv,\n",
              " amazon_reviews_us_Toys_v1_00.tsv,\n",
              " amazon_reviews_us_Office_Products_v1_00.tsv,\n",
              " amazon_reviews_us_Shoes_v1_00.tsv,\n",
              " amazon_reviews_us_Beauty_v1_00.tsv,\n",
              " amazon_reviews_us_Musical_Instruments_v1_00.tsv,\n",
              " amazon_reviews_us_Automotive_v1_00.tsv,\n",
              " amazon_reviews_us_Camera_v1_00.tsv,\n",
              " amazon_reviews_us_Furniture_v1_00.tsv,\n",
              " amazon_reviews_us_Apparel_v1_00.tsv,\n",
              " amazon_reviews_us_Books_v1_02.tsv,\n",
              " amazon_reviews_us_Baby_v1_00.tsv,\n",
              " amazon_reviews_us_Tools_v1_00.tsv,\n",
              " amazon_reviews_us_PC_v1_00.tsv,\n",
              " amazon_reviews_us_Music_v1_00.tsv,\n",
              " amazon_reviews_us_Video_v1_00.tsv,\n",
              " amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv,\n",
              " amazon_reviews_us_Gift_Card_v1_00.tsv,\n",
              " amazon_reviews_us_Digital_Music_Purchase_v1_00.tsv,\n",
              " amazon_reviews_us_Sports_v1_00.tsv,\n",
              " amazon_reviews_us_Major_Appliances_v1_00.tsv,\n",
              " amazon_reviews_us_Wireless_v1_00.tsv,\n",
              " amazon_reviews_us_Video_Games_v1_00.tsv,\n",
              " amazon_reviews_us_Health_Personal_Care_v1_00.tsv,\n",
              " amazon_reviews_us_Pet_Products_v1_00.tsv,\n",
              " amazon_reviews_us_Watches_v1_00.tsv,\n",
              " amazon_reviews_us_Digital_Video_Games_v1_00.tsv]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import kaggle\n",
        "import zipfile\n",
        "\n",
        "# Authenticate Kaggle API\n",
        "kaggle.api.authenticate()"
      ],
      "metadata": {
        "id": "wIqp12HRcApx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle.api.dataset_download_file('cynthiarempel/amazon-us-customer-reviews-dataset','amazon_reviews_us_Digital_Software_v1_00.tsv') # choose dataset among the ones above"
      ],
      "metadata": {
        "id": "xcnhsevyedj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b2d814-5309-43c5-8dbd-01bdd13d535c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the zip file to the current working directory (i.e., the root directory in Colab)\n",
        "with zipfile.ZipFile('amazon_reviews_us_Digital_Software_v1_00.tsv.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()  # Extract to the current directory"
      ],
      "metadata": {
        "id": "Unh-lC3C4sgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import collect_set, col, count\n",
        "from pyspark.sql import SQLContext\n",
        "     \n"
      ],
      "metadata": {
        "id": "5e_ouU-fi8GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = SparkConf().setAppName(\"MarketBasket\")\n",
        "conf = conf.setMaster('local[*]')\n",
        "sc = SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "Cq17_bVmRkcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset import as RDD"
      ],
      "metadata": {
        "id": "x5u6Qn10SxfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sqlContext = SQLContext(sc)\n",
        "# import dataset\n",
        "df = sqlContext.read.csv('amazon_reviews_us_Digital_Software_v1_00.tsv', header=True, sep = '\\t') \n",
        "# subset dataset\n",
        "df = df.select(col(\"customer_id\"),col(\"product_id\"))"
      ],
      "metadata": {
        "id": "BhMAuE1PfLsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sum function\n",
        "def sum_prod(x,y):\n",
        "    return x+y\n",
        "\n",
        "# subset or not function\n",
        "def filtering(rddlist, filt):\n",
        "  for item in filt:\n",
        "    if set(list(item)).issubset(set(rddlist)):\n",
        "      return ((item, 1))"
      ],
      "metadata": {
        "id": "frFUuJngQxtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A-priori algorithm"
      ],
      "metadata": {
        "id": "9r1dsKyRSWPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apriori(rdd, threshold):\n",
        "  \n",
        "  flat_list  = rdd.flatMap(list) \n",
        "\n",
        "  singleton = flat_list.map(lambda item: (item , 1)) # (item, 1)\n",
        "  singleton_summed = singleton.reduceByKey(sum_prod) # sum by key\n",
        "  singleton_filtered = singleton_summed.filter(lambda item: item[1] >= threshold ) # check threshold\n",
        "\n",
        "  # items filtered\n",
        "  frequent_prod = singleton_filtered.map(lambda item: (item[0]))\n",
        "\n",
        "  # candidate pairs\n",
        "  pairs_list = list(itertools.combinations(frequent_prod.toLocalIterator(),2))\n",
        "\n",
        "  # pairs are subset of baskets?\n",
        "  support_table_pairs = rdd.map(lambda x : filtering(x, pairs_list)).filter(lambda x: x is not None).cache() \n",
        "  support_table_pairs_summed = support_table_pairs.reduceByKey(sum_prod) # sum by key\n",
        "  support_table_pairs_filtered = support_table_pairs_summed.filter(lambda item: item[1] >= threshold) # check threshold\n",
        "\n",
        "  return (support_table_pairs_filtered)\n"
      ],
      "metadata": {
        "id": "3MXUJLpuQ3Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SON algorithm "
      ],
      "metadata": {
        "id": "C6VnEv7vSeBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# available baskets\n",
        "baskets = df.groupBy(\"customer_id\").agg(collect_set(\"product_id\").alias(\"product_id\"))\n",
        "\n",
        "# available baskets\n",
        "basket_list = baskets.select('product_id').rdd.flatMap(list)\n",
        "\n",
        "# Parallelize the list in RDD\n",
        "basket_list = sc.parallelize(basket_list.collect(), 5)"
      ],
      "metadata": {
        "id": "Eh_4nWH-W96u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minSupport = 35 # definition of threshold\n",
        "numPartitions = basket_list.getNumPartitions() # get number of partition (5 in this case)\n",
        "adjSupport = minSupport/numPartitions # threshold for each partition\n",
        "adjSupport"
      ],
      "metadata": {
        "id": "9e8XMvFYXAGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools"
      ],
      "metadata": {
        "id": "9c4XVXYIYefK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidates = sc.parallelize([]) # create a RDD to merge the result of apriori applied on each chunk\n",
        "\n",
        "for i in range(0, numPartitions-1):\n",
        "  partition = sc.parallelize(basket_list.glom().collect()[i]) # collect each partition\n",
        "  support_table_pairs_filtered = apriori(partition, adjSupport) # apply apriori to each partition\n",
        "  candidate_chunk = support_table_pairs_filtered.map(lambda item: (item[0],1)) # (item, 1)\n",
        "  candidates = candidates.union(candidate_chunk) # all in one"
      ],
      "metadata": {
        "id": "E5rWOjXgXEGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidates_prods = candidates.map(lambda item : item[0]) \n",
        "candidates_list = candidates_prods.collect() # more time comsuming"
      ],
      "metadata": {
        "id": "zvc04hK2XTu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidates_check = basket_list.map(lambda x : filtering(x, candidates_list)).filter(lambda x: x is not None).cache() # subset or not\n",
        "candidates_summed = candidates_check.reduceByKey(sum_prod) # sum by key\n",
        "candidates_filtered = candidates_summed.filter(lambda item: item[1] >= minSupport) # check threshold"
      ],
      "metadata": {
        "id": "9kvaWvimXV40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "mkBQKgwYS7QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of all products    \n",
        "flat_list  = basket_list.flatMap(list)\n",
        "\n",
        "# obtain the products that appear in a number of baskets larger than the threshold:\n",
        "singleton = flat_list.map(lambda item: (item , 1)) # add one for each product appearence\n",
        "singleton_summed = singleton.reduceByKey(sum_prod) # sum of values by product as key\n",
        "singleton_filtered = singleton_summed.filter(lambda item: item[1] >= minSupport ) # consider just the product that performed in more than support value"
      ],
      "metadata": {
        "id": "556GSMvIXadS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "singleton_filtered.sortBy(lambda x: x[1], ascending=False).take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agBdhyYKit7_",
        "outputId": "74af5722-8f4b-458b-a32d-8d65ef59aa6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('B00H9A60O4', 9468),\n",
              " ('B00NG7JVSQ', 6308),\n",
              " ('B00E7X9RUK', 2245),\n",
              " ('B00M9GTHS4', 2208),\n",
              " ('B00PG8FOSY', 1936),\n",
              " ('B008S0IMCC', 1923),\n",
              " ('B00FGDDTSQ', 1800),\n",
              " ('B00M76N6MO', 1686),\n",
              " ('B0064PFB9U', 1585),\n",
              " ('B00B1TGUMG', 1450)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "candidates_filtered.sortBy(lambda x: x[1], ascending=False).take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF1kH-i1jaVS",
        "outputId": "e4942357-3fa2-44c4-aa77-1a278a8118a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('B008SCNLEY', 'B00FGDDTSQ'), 84),\n",
              " (('B009HBCU9W', 'B00FFINOWS'), 83),\n",
              " (('B00FFINOWS', 'B00NG7JVSQ'), 78),\n",
              " (('B00G0DXA9Y', 'B00PG8FOSY'), 63),\n",
              " (('B008SCMUUA', 'B00FGDEPDY'), 60),\n",
              " (('B00A42LWHO', 'B00G0DXA9Y'), 49),\n",
              " (('B00M9GTHS4', 'B00E7X9RUK'), 49),\n",
              " (('B00NG7JVSQ', 'B00PG8FOSY'), 43),\n",
              " (('B00NG7JVSQ', 'B00NG7K2RA'), 37)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}